{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1., -3.1, -7.2, 2.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X):\n",
    "    return -3 + 2.1 * X[0] + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return x if x > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, it will look like a sequence of layers \n",
    "model = Sequential()\n",
    "\n",
    "# First layer: 10 neurons and ReLU as the activation function\n",
    "model.add(layers.Dense(10, activation='relu')) \n",
    "\n",
    "# Disclaimer: The standard layers are called Fully Connected (Dense in Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can go for two fully connected layers\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also go for many, many, many more ...\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='linear'))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(40, activation='softmax'))\n",
    "model.add(layers.Dense(10, activation='tanh'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='tanh'))\n",
    "model.add(layers.Dense(8900, activation='relu'))\n",
    "model.add(layers.Dense(1000, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small exercice: how many parameters in this simple regression task: \n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "manual calculation =  55050\n",
      "manual calculation: 55050\n"
     ]
    }
   ],
   "source": [
    "# Answer : Use the summary() function to keep track of what you are doing\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(784,), activation='relu'))\n",
    "model.add(layers.Dense(64, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "print(\"manual calculation = \", (64*784 + 64) + (64*64 + 64) + (10*64 + 10))\n",
    "print(f'manual calculation: {64 * (784 + 1) + 64 * (64 + 1) + 10* (64 + 1)}')\n",
    "\n",
    "# Number of params is the neurons of one layer multiplied by the input plus one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa77d619d6dcdd36e8fd5689d2f52630df74221f02267f9c7440a3f32faeaec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
