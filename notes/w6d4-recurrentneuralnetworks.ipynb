{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "## CCN reminders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 09:08:11.650550: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-18 09:08:11.654282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 09:08:11.654292: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-18 09:08:13.871326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-18 09:08:13.871362: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 09:08:13.871375: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (RSOLE): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 09:08:13.871557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), \n",
    "                 padding='same',\n",
    "                 strides = (1,1),\n",
    "                 input_shape=(32, 32, 3), \n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 24s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# This is optional, depending if you have time & will to update the first layers\n",
    "model.trainable = False\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(100, activation='relu')\n",
    "prediction_layer = layers.Dense(10, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    model, \n",
    "    flatten_layer, \n",
    "    dense_layer, \n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- SEQUENCE A (Paris)\n",
    "\n",
    "day_1 = [10, 25, 50]  # OBSERVATION 1 [Temp, speed, pollution]\n",
    "day_2 = [13, 10, 70]  # OBSERVATION 2 [Temp, speed, pollution]\n",
    "day_3 = [ 9,  5, 90]\n",
    "day_4 = [ 7,  0, 95]\n",
    "\n",
    "sequence_a = [day_1, day_2, day_3, day_4]\n",
    "\n",
    "y_a = 110 # Pollution day 5\n",
    "\n",
    "# --- SEQUENCE B (Berlin)\n",
    "sequence_b = [[25, 20, 30], [26, 24, 50], [28, 20, 80], [22, 3, 110]]\n",
    "y_b = 125\n",
    "\n",
    "# --- SEQUENCE C (London)\n",
    "sequence_c = [[15, 10, 60], [25, 20, 65], [35, 10, 75], [36, 15, 70]]\n",
    "y_c = 30\n",
    "\n",
    "X = np.array([sequence_a, sequence_b, sequence_c]).astype(np.float32)\n",
    "y = np.array([y_a, y_b, y_c]).astype(np.float32)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.9255787 ],\n",
       "       [-0.99157965],\n",
       "       [-0.9916189 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ––– It is very easy to code\n",
    "\n",
    "from keras.api._v2.keras.models import Sequential\n",
    "from keras.api._v2.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SimpleRNN(units=2, activation='tanh', input_shape=(4,3)))\n",
    "model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "# The compilation\n",
    "model.compile(loss='mse', \n",
    "              optimizer='rmsprop')  # Recommended optimizer for RNNs\n",
    "# The fit\n",
    "model.fit(X, y,\n",
    "         batch_size=16,\n",
    "         epochs=10, verbose=0)\n",
    "\n",
    "# The prediction (one per sequence/city)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_x = 3 # features (temp, speed, pollution)\n",
    "n_h = 2 # units = neurons\n",
    "\n",
    "# number of weights\n",
    "n_h * n_x + n_h * n_h + n_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- NEW CITY ----\n",
    "x = [[10, 25, 50],  # x1\n",
    "     [13, 10, 70],  # x2\n",
    "     [ 9,  5, 90],  # x3\n",
    "     [ 7,  0, 95]]  # x4\n",
    "\n",
    "y4 = # Pollution day 4+1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (3, 4, 3)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape: \", X.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2), (2, 2), (2,)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.numpy().shape for w in model.layers[0].weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 10)                140       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take this model with 10 RNN units\n",
    "model_10 = Sequential()\n",
    "model_10.add(layers.SimpleRNN(units=10))\n",
    "model_10.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "model_10.compile(loss='mse', optimizer='rmsprop')\n",
    "model_10.fit(X, y, batch_size=16, epochs=10, verbose=0)\n",
    "model_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 3)\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- SEQUENCE A (Paris)\n",
    "\n",
    "sequence_a = [[10, 25, 50],  # OBS day 1\n",
    "              [13, 10, 70],  # OBS day 2\n",
    "              [ 9,  5, 90],  # OBS day 3\n",
    "              [ 7,  0, 95]]  # OBS day 4\n",
    "\n",
    "y_a = [70,   # flu cases day 1\n",
    "       90,   # flu cases day 2\n",
    "       95,   # flu cases day 3\n",
    "       110,] # flu cases day 4\n",
    "\n",
    "# --- SEQUENCE B (Berlin)\n",
    "sequence_b = [[25, 20, 30], [26, 24, 50], [28, 20, 80], [22, 3, 110]]\n",
    "y_b = [50, 80, 110, 125]\n",
    "\n",
    "# --- SEQUENCE C (London)\n",
    "sequence_c = [[15, 10, 60], [25, 20, 65], [35, 10, 75], [36, 15, 70]]\n",
    "y_c = [65, 75, 70, 30]\n",
    "\n",
    "X = np.array([sequence_a, sequence_b, sequence_c]).astype(np.float32)\n",
    "y = np.array([y_a, y_b, y_c]).astype(np.float32)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1287e6b520>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(layers.SimpleRNN(2, return_sequences=True))\n",
    "model_2.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "model_2.compile(loss='mse', optimizer='rmsprop')\n",
    "model_2.fit(X, y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step\n",
      "y_pred shape: (3, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred shape:\", model_2.predict(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, 4, 10)             140       \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 3)                 42        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_stacked = Sequential()\n",
    "\n",
    "model_stacked.add(layers.SimpleRNN(10, return_sequences=True, input_shape=((4, 3)))) \n",
    "model_stacked.add(layers.SimpleRNN(3, return_sequences=False))\n",
    "model_stacked.add(Dense(1, activation='relu'))\n",
    "\n",
    "model_stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api._v2.keras.layers import SimpleRNN, LSTM, GRU\n",
    "\n",
    "###  Simple RNN  ###\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10, activation='tanh'))  \n",
    "\n",
    "###  LSTM   ###\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=10, activation='tanh'))\n",
    "\n",
    "###  GRU ###\n",
    "model = Sequential()\n",
    "model.add(GRU(units=10, activation='tanh'))\n",
    "\n",
    "# Compile with 'rmsprop' rather than 'adam' (recommended)\n",
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs of different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- SEQUENCE 1 (Paris) ---\n",
    "\n",
    "sequence_1 = [[10, 25, 50],  # OBS day 1\n",
    "              [13, 10, 70],  # OBS day 2\n",
    "              [ 9,  5, 90],  # OBS day 3\n",
    "              [ 7,  0, 95]]  # OBS day 4\n",
    "\n",
    "y_1 = 110 # pollution day 5 \n",
    "\n",
    "# --- SEQUENCE 2 (Berlin) ---\n",
    "sequence_2 = [[25, 20, 30],\n",
    "              [26, 24, 50]]\n",
    "\n",
    "y_2 = 125 # pollution day 3\n",
    "\n",
    "# --- SEQUENCE 3 (London)\n",
    "sequence_3 = [[15, 10, 60],\n",
    "              [25, 20, 65],\n",
    "              [35, 10, 75]]\n",
    "y_3 = 30 # Pollution day 4\n",
    "\n",
    "X = [sequence_1, sequence_2, sequence_3]\n",
    "X = [np.array(_) for _ in X]\n",
    "y = np.array([y_1, y_2, y_3]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 4, 2, 3\n  y sizes: 3\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2791/3420182448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# The fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1654\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 4, 2, 3\n  y sizes: 3\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(1, activation='tanh')) \n",
    "model.add(Dense(1, activation=\"relu\"))\n",
    "\n",
    "# The compilation\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "# The fit\n",
    "model.fit(X, y, batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10., 25., 50.],\n",
       "        [13., 10., 70.],\n",
       "        [ 9.,  5., 90.],\n",
       "        [ 7.,  0., 95.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [25., 20., 30.],\n",
       "        [26., 24., 50.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [15., 10., 60.],\n",
       "        [25., 20., 65.],\n",
       "        [35., 10., 75.]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_pad = pad_sequences(X, dtype='float32') # int32 by default\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   10.,    25.,    50.],\n",
       "        [   13.,    10.,    70.],\n",
       "        [    9.,     5.,    90.],\n",
       "        [    7.,     0.,    95.]],\n",
       "\n",
       "       [[   25.,    20.,    30.],\n",
       "        [   26.,    24.,    50.],\n",
       "        [-1000., -1000., -1000.],\n",
       "        [-1000., -1000., -1000.]],\n",
       "\n",
       "       [[   15.,    10.,    60.],\n",
       "        [   25.,    20.,    65.],\n",
       "        [   35.,    10.,    75.],\n",
       "        [-1000., -1000., -1000.]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad = pad_sequences(X, dtype='float32', padding='post', value=-1000)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 812ms/step - loss: 9532.3359\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Masking\n",
    "\n",
    "# –– Data\n",
    "X = pad_sequences(X, dtype='float32', padding='post', value=-1000)\n",
    "# X.shape == (3,4,3)\n",
    "\n",
    "# –– Model\n",
    "model = Sequential()\n",
    "model.add(layers.Masking(mask_value=-1000, input_shape=(4,3)))\n",
    "model.add(layers.SimpleRNN(units=2, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# –– Compilation\n",
    "model.compile(loss='mse', \n",
    "              optimizer='rmsprop') # Use `rmsprop`\n",
    "\n",
    "# –– Fit\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa77d619d6dcdd36e8fd5689d2f52630df74221f02267f9c7440a3f32faeaec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
